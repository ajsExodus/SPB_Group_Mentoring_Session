{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Companion to the Springboard DSC <i>Group Mentoring Sessions</i> on Data Wrangling\n",
    "\n",
    "These sessions were offered by Springboard on August 12 & 26/2023, and facilitated by AJ Sanchez, who has been a mentor with the <i>Data Science Career Track Program</i> since 2016.\n",
    "\n",
    "Thanks to Dhara Damiana, Operations Manager with Springboard, who was in charge of the logistics.\n",
    "\n",
    "To work on this notebook I used [Visual Studio Code](https://code.visualstudio.com/) (VS Code), which I also use in my professional work. One of the many advantages of using VS Code is that it automatically generates a clickable outline. I also created a separate [Conda Environment](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) running [Python 3.11.0](https://www.python.org/downloads/release/python-3110/), and other packages such as [Pandas 2.0.3](https://pandas.pydata.org/docs/getting_started/install.html), [ydata-profiling 4.5.1](https://pypi.org/project/ydata-profiling/), etc. \n",
    "\n",
    "I used a laptop running under [Ubuntu 22.04.3 LTS](https://releases.ubuntu.com/jammy/).\n",
    "\n",
    "<b>Disclaimer</b>:\n",
    "The code presented here should not be construed as representing or coming from Springboard. This code is being shared for educational and informational purposes only, and should not be construed as professional advice. For professional Data Science and Software Engineering advice and services, please get in touch with the author of the code by sending email as indicated below.\n",
    "\n",
    "<b>Contact</b>: AJ Sanchez (`ajs@ExodusSoftServices.com`)--Data Science Mentor.\n",
    "\n",
    "V1: 8/25/2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Exercise:\n",
    "\n",
    "<i>Do just what is needed to “Acquire and prepare the data for further analysis” for the dataset I shared with you via email before today. If you started to work on the wrangling of this dataset, compare your approach with the minimal approach discussed here, and consider sharing your thoughts and work with the audience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This exercise uses the dataset `Inc 5000 Companies` available from [Kaggle](https://www.kaggle.com/datasets/mysarahmadbhat/inc-5000-companies?resource=download).\n",
    "\n",
    ">\"<i>Dataset containing information about each company on the INC 5000 list in 2019. Dataset containing information about each company on the INC 5000 list in 2019. Fields include the company name, industry, founding year, website, and location, as well as 2019 revenue, % growth, number of workers (year-over-year), and the number of years on the list.</i>\"\n",
    "#### 0.0 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Get the Data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './DATA/INC 5000 Companies 2019.csv'\n",
    "companies_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Row and Column Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 5012 companies, and 14 potential features per company ...'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions\n",
    "(n_companies, n_features) = companies_df.shape\n",
    "\"There are \" + str(n_companies) + \" companies, and \" + str(n_features) + \" potential features per company ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Types and Semantics\n",
    "\n",
    "<b>Types:</b> Refer to the type of values in a column according to [Python's type system](https://docs.python.org/3/library/datatypes.html). Strictly speaking, values in a Pandas DataFrame are described by [`dtypes`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html). See also [this reference](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes). Of course, `dtypes` can be mapped to Python types.\n",
    "\n",
    "<b>Semantics:</b> Refer to the intended meaning of a value in a dataset column, and this is usually application-dependent. For instance, a value of `40.0` under column `workers` probably means the number of workers in the corresponding company.\n",
    "\n",
    "Notice that Types and Semantics might not align according to what one would expect. For instance, values associated `workers` might be of (Python) [`string` type](https://docs.python.org/3/library/string.html)--instead of being of type [`int`](https://docs.python.org/3/library/stdtypes.html?highlight=integer#numeric-types-int-float-complex), and therefore its Pandas `dtype` would be `object`. This is the case of column `revenue` in this dataset.\n",
    "\n",
    "In most instances, these two characteristics of the columns of a dataset can be easily inferred from: domain knowledge, column names, column values, etc. However, there might be cases for which the intended meaning of a column is not disclosed--for whatever reason, which might also be undisclosed. Whatever the case might be, Data Scientist must always work in close cooperation with domain experts and clients to determine these two characteristics.\n",
    "\n",
    "A good practice to document the Types and Semantics of columns is to keep track of them in what is usually referred to as a <i>Data Dictionary</i>, which is simply a table with--for instance--the following columns: Column Name, Type, Semantics, Expected Values, Sample Values, and Notes. One would use the Expected Values column of the Data Dictionary to perform <i>Data Quality Checks</i> per column. The Data Dictionary might be already available from the client, so be sure to ask if it is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>profile</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>state</th>\n",
       "      <th>revenue</th>\n",
       "      <th>growth_%</th>\n",
       "      <th>industry</th>\n",
       "      <th>workers</th>\n",
       "      <th>previous_workers</th>\n",
       "      <th>founded</th>\n",
       "      <th>yrs_on_list</th>\n",
       "      <th>metro</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.inc.com/profile/freestar</td>\n",
       "      <td>Freestar</td>\n",
       "      <td>http://freestar.com</td>\n",
       "      <td>AZ</td>\n",
       "      <td>36.9 Million</td>\n",
       "      <td>36680.3882</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.inc.com/profile/freightwise</td>\n",
       "      <td>FreightWise</td>\n",
       "      <td>http://freightwisellc.com</td>\n",
       "      <td>TN</td>\n",
       "      <td>33.6 Million</td>\n",
       "      <td>30547.9317</td>\n",
       "      <td>Logistics &amp; Transportation</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>Brentwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.inc.com/profile/ceces-veggie</td>\n",
       "      <td>Cece's Veggie Co.</td>\n",
       "      <td>http://cecesveggieco.com</td>\n",
       "      <td>TX</td>\n",
       "      <td>24.9 Million</td>\n",
       "      <td>23880.4852</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>190.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.inc.com/profile/ladyboss</td>\n",
       "      <td>LadyBoss</td>\n",
       "      <td>http://ladyboss.com</td>\n",
       "      <td>NM</td>\n",
       "      <td>32.4 Million</td>\n",
       "      <td>21849.8925</td>\n",
       "      <td>Consumer Products &amp; Services</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albuquerque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.inc.com/profile/perpay</td>\n",
       "      <td>Perpay</td>\n",
       "      <td>http://perpay.com</td>\n",
       "      <td>PA</td>\n",
       "      <td>22.5 Million</td>\n",
       "      <td>18166.4070</td>\n",
       "      <td>Retail</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://www.inc.com/profile/cano-health</td>\n",
       "      <td>Cano Health</td>\n",
       "      <td>http://canohealth.com</td>\n",
       "      <td>FL</td>\n",
       "      <td>271.8 Million</td>\n",
       "      <td>14183.4118</td>\n",
       "      <td>Health</td>\n",
       "      <td>742.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://www.inc.com/profile/bear-mattress</td>\n",
       "      <td>Bear Mattress</td>\n",
       "      <td>http://bearmattress.com</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20.5 Million</td>\n",
       "      <td>13480.7310</td>\n",
       "      <td>Consumer Products &amp; Services</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Hoboken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://www.inc.com/profile/connected-solution...</td>\n",
       "      <td>Connected Solutions Group</td>\n",
       "      <td>http://csgstore.net</td>\n",
       "      <td>VA</td>\n",
       "      <td>23.3 Million</td>\n",
       "      <td>12700.6588</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>Mechanicsville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://www.inc.com/profile/providence-healthc...</td>\n",
       "      <td>Providence Healthcare Management</td>\n",
       "      <td>http://providencehcm.com</td>\n",
       "      <td>OH</td>\n",
       "      <td>225.9 Million</td>\n",
       "      <td>12564.5364</td>\n",
       "      <td>Health</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://www.inc.com/profile/nom</td>\n",
       "      <td>NOM</td>\n",
       "      <td>http://thisisnom.co</td>\n",
       "      <td>CA</td>\n",
       "      <td>21.4 Million</td>\n",
       "      <td>11996.2964</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                            profile  \\\n",
       "0     1               https://www.inc.com/profile/freestar   \n",
       "1     2            https://www.inc.com/profile/freightwise   \n",
       "2     3           https://www.inc.com/profile/ceces-veggie   \n",
       "3     4               https://www.inc.com/profile/ladyboss   \n",
       "4     5                 https://www.inc.com/profile/perpay   \n",
       "5     6            https://www.inc.com/profile/cano-health   \n",
       "6     7          https://www.inc.com/profile/bear-mattress   \n",
       "7     8  https://www.inc.com/profile/connected-solution...   \n",
       "8     9  https://www.inc.com/profile/providence-healthc...   \n",
       "9    10                    https://www.inc.com/profile/nom   \n",
       "\n",
       "                               name                        url state  \\\n",
       "0                          Freestar        http://freestar.com    AZ   \n",
       "1                       FreightWise  http://freightwisellc.com    TN   \n",
       "2                 Cece's Veggie Co.   http://cecesveggieco.com    TX   \n",
       "3                          LadyBoss        http://ladyboss.com    NM   \n",
       "4                            Perpay          http://perpay.com    PA   \n",
       "5                       Cano Health      http://canohealth.com    FL   \n",
       "6                     Bear Mattress    http://bearmattress.com    NJ   \n",
       "7         Connected Solutions Group        http://csgstore.net    VA   \n",
       "8  Providence Healthcare Management   http://providencehcm.com    OH   \n",
       "9                               NOM        http://thisisnom.co    CA   \n",
       "\n",
       "         revenue    growth_%                      industry  workers  \\\n",
       "0   36.9 Million  36680.3882       Advertising & Marketing     40.0   \n",
       "1   33.6 Million  30547.9317    Logistics & Transportation     39.0   \n",
       "2   24.9 Million  23880.4852               Food & Beverage    190.0   \n",
       "3   32.4 Million  21849.8925  Consumer Products & Services     57.0   \n",
       "4   22.5 Million  18166.4070                        Retail     25.0   \n",
       "5  271.8 Million  14183.4118                        Health    742.0   \n",
       "6   20.5 Million  13480.7310  Consumer Products & Services     12.0   \n",
       "7   23.3 Million  12700.6588            Telecommunications     72.0   \n",
       "8  225.9 Million  12564.5364                        Health     60.0   \n",
       "9   21.4 Million  11996.2964       Advertising & Marketing     37.0   \n",
       "\n",
       "   previous_workers  founded  yrs_on_list          metro            city  \n",
       "0                 5     2015            1        Phoenix         Phoenix  \n",
       "1                 8     2015            1      Nashville       Brentwood  \n",
       "2                10     2015            1         Austin          Austin  \n",
       "3                 2     2014            1            NaN     Albuquerque  \n",
       "4                 6     2014            1   Philadelphia    Philadelphia  \n",
       "5                18     2009            1          Miami           Miami  \n",
       "6                 1     2014            1  New York City         Hoboken  \n",
       "7                 1     2015            1   Richmond, VA  Mechanicsville  \n",
       "8                10     2008            1      Cleveland       Cleveland  \n",
       "9                 5     2014            1    Los Angeles     Los Angeles  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the dataset\n",
    "companies_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growth_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_workers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrs_on_list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [rank, profile, name, url, state, revenue, growth_%, industry, workers, previous_workers, founded, yrs_on_list, metro, city]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also see the columns in a nice format\n",
    "companies_df.head(0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case, it seems that it would be easy to infer the semantics from the names of the columns. This could be a good time to begin to build the data dictionary--if none is available--and then check with the client and/or domain experts the correctness of our summary, and most importantly to ask about potential semantic rules that must be checked. Examples include: zip codes, phone numbers, social security numbers, money, age, etc.\n",
    "\n",
    "One simple way to have a quick initial idea of the types of values in a Dataframe is to use `dtypes`, which is a <i>property</i> of a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                  int64\n",
       "profile              object\n",
       "name                 object\n",
       "url                  object\n",
       "state                object\n",
       "revenue              object\n",
       "growth_%            float64\n",
       "industry             object\n",
       "workers             float64\n",
       "previous_workers      int64\n",
       "founded               int64\n",
       "yrs_on_list           int64\n",
       "metro                object\n",
       "city                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the dtypes of values in the DF\n",
    "companies_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection shows that there seems to be an intuitively correct association between the expected semantics of each column and the `dtype` associated with its values. To see the difference between the Python type of an object and its Pandas' `dtype`, one would take a look at `type(x)`, where `x` is a value or a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for instance, the type of companies_df\n",
    "type(companies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the type of **one** value randomly selected from column 'revenue' of companies_df\n",
    "# REF: https://docs.python.org/3/library/random.html\n",
    "import random\n",
    "type(random.choice(companies_df['revenue'].to_list()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that randomly selected value of that column is of type [str](https://docs.python.org/3/library/stdtypes.html) (string).\n",
    "\n",
    "Now, it is possible for a `DataFrame` column to have (Python) values of different types. Therefore, in order to check the types of all the values in a column, we could do something like this ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{str}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the set of all types of values in column 'revenue'\n",
    "# we take advantage of the fact that values in a Python set cannot\n",
    "# appear multiple times in it\n",
    "# REF: https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset\n",
    "set([type(x) for x in companies_df['revenue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, all the values in the column are of type `str`. I will come back to this column later when we perform data quality checks on it.\n",
    "\n",
    "Meanwhile, it would be nice to have a little helper function such that given any `DataFrame`, returns a `DataFrame` with all the Python types for the values of all the columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "> Inputs:\n",
    "\n",
    "  * the_df: a DataFrame\n",
    "  \n",
    "> Assumptions (conditions that are required and not checked for\n",
    "  the purposes of this assignment, and this is left as an exercise for the\n",
    "  reader):\n",
    "  \n",
    "  * The parameters have the expected types\n",
    "  * the_df is not empty\n",
    "  \n",
    "> Returns:\n",
    "\n",
    "  * A DataFrame with the names of the columns in the_df, and\n",
    "  the types associated with each column\n",
    "\n",
    "'''\n",
    "def get_types_of_df(the_df):\n",
    "\n",
    "    # get the columns of the_df\n",
    "    # they will be the columns of\n",
    "    # the result to be returned by this function\n",
    "    the_cols = list(the_df)\n",
    "\n",
    "    # iterate over the set of columns to\n",
    "    # compute the types of values in the column\n",
    "    # keep track of them in a dict\n",
    "    the_types = []\n",
    "    for the_col in the_cols:\n",
    "        # compute the set of types for the values in the_col\n",
    "        # and save a string representation of it in the_types\n",
    "        the_types += [set([type(x) for x in the_df[the_col]])]\n",
    "    # end for\n",
    "\n",
    "    # create the DataFrame and return it ... TBTG!!!\n",
    "    return pd.DataFrame({'Column Name': the_cols, 'Column Type': the_types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>3.149267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A            B\n",
       "0           1     1.000000\n",
       "1          hi          NaN\n",
       "2         3.0          NaN\n",
       "3  2023-08-25     3.149267\n",
       "4        None  2023.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it first on a simple DataFrame\n",
    "from datetime import date\n",
    "test_df = pd.DataFrame({'A': [1, \"hi\", 3.0, date(2023,8, 25), None], \n",
    "                       'B': [1, None, float('nan'), 3.14926735, 2023]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     object\n",
       "B    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what dtypes gives us ...\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Column Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>{&lt;class 'float'&gt;, &lt;class 'datetime.date'&gt;, &lt;cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>{&lt;class 'float'&gt;}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column Name                                        Column Type\n",
       "0           A  {<class 'float'>, <class 'datetime.date'>, <cl...\n",
       "1           B                                  {<class 'float'>}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function\n",
    "types_df = get_types_of_df(test_df)\n",
    "types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column Name                                                                                   Column Type\n",
      "0           A  {<class 'float'>, <class 'datetime.date'>, <class 'int'>, <class 'NoneType'>, <class 'str'>}\n",
      "1           B                                                                             {<class 'float'>}\n"
     ]
    }
   ],
   "source": [
    "# notice that we cannot see all the types for column 'A'\n",
    "# I needed to look for a trick to solve this issue, and the\n",
    "# fix is simple in this case ...\n",
    "print(types_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `None` and `float('nan')` are handled by the `DataFrame` constructor ... something to think about ... :-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column Name                       Column Type\n",
      "0               rank                   {<class 'int'>}\n",
      "1            profile                   {<class 'str'>}\n",
      "2               name                   {<class 'str'>}\n",
      "3                url                   {<class 'str'>}\n",
      "4              state                   {<class 'str'>}\n",
      "5            revenue                   {<class 'str'>}\n",
      "6           growth_%                 {<class 'float'>}\n",
      "7           industry                   {<class 'str'>}\n",
      "8            workers                 {<class 'float'>}\n",
      "9   previous_workers                   {<class 'int'>}\n",
      "10           founded                   {<class 'int'>}\n",
      "11       yrs_on_list                   {<class 'int'>}\n",
      "12             metro  {<class 'float'>, <class 'str'>}\n",
      "13              city                   {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# test the function with the companies DF\n",
    "print(get_types_of_df(companies_df).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly our function gives us more detailed information than `dtypes`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Profiling and Tableau\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> I will install [Pandas Profiling](https://pypi.org/project/pandas-profiling/), which is now called `ydata-profiling`, in this environment.\n",
    "\n",
    ">`pip install ydata-profiling`\n",
    "\n",
    "It seems that I also need to install ...\n",
    "\n",
    "`conda install -c conda-forge ipywidgets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the docs ...\n",
    "# https://ydata-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(companies_df, title=\"Pandas Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to HTML\n",
    "profile.to_file(\"Companies.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Open HTML file (`Companies.html`) in browser and let's give it a quick look</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> In many cases, it might be faster and easier to use Tableau! I am showing some views I generated with Tableau using just \"drag-and-drop\" operations. They are in the `DATA` folder; which is in the folder where this notebook is stored.\n",
    "\n",
    "<img src=\"./Kaggle_Dataset_SUMMARY.png\">\n",
    "\n",
    "<img src=\"./Kaggle_Dataset_COMPANY_MAP.png\">\n",
    "\n",
    "<img src=\"./Kaggle_Dataset_Screenshot_INDUSTRIES.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Checking Semantics of `revenue`\n",
    "\n",
    "Per the type analysis discussed above ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column Name        Column Type\n",
      "0               rank    {<class 'int'>}\n",
      "1            profile    {<class 'str'>}\n",
      "2               name    {<class 'str'>}\n",
      "3                url    {<class 'str'>}\n",
      "4              state    {<class 'str'>}\n",
      "5            revenue    {<class 'str'>}\n",
      "6           growth_%  {<class 'float'>}\n",
      "7           industry    {<class 'str'>}\n",
      "8            workers  {<class 'float'>}\n",
      "9   previous_workers    {<class 'int'>}\n",
      "10           founded    {<class 'int'>}\n",
      "11       yrs_on_list    {<class 'int'>}\n",
      "12             metro    {<class 'str'>}\n",
      "13              city    {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "print(get_types_of_df(companies_df).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... column `revenue` contains string values, and if the semantics is that these values should a float `float` amount representing US Dollars, then this would be the approriate place to fix that (meaning, during Data Wrangling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the values\n",
    "\n",
    "revenue_col = list(companies_df['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{str}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see types\n",
    "set([type(x) for x in revenue_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'36.9 Million'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they are all string ...\n",
    "# see one of the values\n",
    "revenue_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Billion', 'Million'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see distinct suffixes\n",
    "set([x.split(' ')[1] for x in revenue_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these two new columns: revenue_amount, revenue_units\n",
    "revenue_amount = [float(x.split(' ')[0].strip()) for x in revenue_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_units = [x.split(' ')[1].strip() for x in revenue_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 990.6, 31.086592178771006)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick stats\n",
    "min(revenue_amount), max(revenue_amount), sum(revenue_amount) / (len(revenue_amount) * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Billion', 'Million'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and units\n",
    "set(revenue_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns to dataset\n",
    "companies_df['revenue_amount'] = revenue_amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df['revenue_units'] = revenue_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_amount</th>\n",
       "      <th>revenue_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.9</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.6</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.9</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.4</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.5</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>15.8</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>11.6</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>29.7</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>8.8</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>4.5</td>\n",
       "      <td>Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      revenue_amount revenue_units\n",
       "0               36.9       Million\n",
       "1               33.6       Million\n",
       "2               24.9       Million\n",
       "3               32.4       Million\n",
       "4               22.5       Million\n",
       "...              ...           ...\n",
       "5007            15.8       Million\n",
       "5008            11.6       Million\n",
       "5009            29.7       Million\n",
       "5010             8.8       Million\n",
       "5011             4.5       Million\n",
       "\n",
       "[5012 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check again types\n",
    "companies_df[['revenue_amount', 'revenue_units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column Name        Column Type\n",
      "0  revenue_amount  {<class 'float'>}\n",
      "1   revenue_units    {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# check types now\n",
    "print(get_types_of_df(companies_df[['revenue_amount', 'revenue_units']]).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Missing Values and Some Little Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# I need a function that I can use to explore missing values associated\n",
    "# with a subset of a DF ... a simple one first\n",
    "#\n",
    "def get_percent_missing_values_sub_df(the_df, the_col, the_value):\n",
    "    # \n",
    "\n",
    "    # get the sub DF ... if the_col is None, assume that we want to use the\n",
    "    # whole DF ... the_value is ignored ...\n",
    "    if the_col is None:\n",
    "        # we want all columns\n",
    "        sub_df = the_df\n",
    "    else:\n",
    "        # the_col can be a string (name of column), or a list of strings (subset of columns)\n",
    "        # in the first case, we expect a value to compare the values of the column against\n",
    "        # in the second case, we do not need a value, and the_col should be a list of names,\n",
    "        # which can have only one name\n",
    "        sub_df = the_df.loc[the_df[the_col] == the_value] if the_value is not None else the_df[the_col]\n",
    "    # end if\n",
    "\n",
    "    # build the_result_df with number of missing values of sub_df\n",
    "    # get dimensions\n",
    "    (n_rows, n_cols) = sub_df.shape\n",
    "    the_result_df = pd.DataFrame({'Raw Feature Name': list(sub_df),\n",
    "                                  'Percent Missing Values': (sub_df.isnull().sum() * 100.0 / n_rows).to_list()})\n",
    "    # sort it descendently before returning\n",
    "    the_result_df.sort_values('Percent Missing Values', inplace=True, ascending=False)\n",
    "\n",
    "    # that's it ... return the result\n",
    "    return n_rows, n_cols, the_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it with companies_df\n",
    "n_rows, n_cols, the_result_df = get_percent_missing_values_sub_df(the_df=companies_df, \n",
    "                                                                  the_col=None, \n",
    "                                                                  the_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature Name</th>\n",
       "      <th>Percent Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>metro</td>\n",
       "      <td>16.221069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workers</td>\n",
       "      <td>0.019952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rank</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>profile</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>url</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>revenue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>growth_%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>industry</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>previous_workers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>founded</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yrs_on_list</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>city</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Raw Feature Name  Percent Missing Values\n",
       "12             metro               16.221069\n",
       "8            workers                0.019952\n",
       "0               rank                0.000000\n",
       "1            profile                0.000000\n",
       "2               name                0.000000\n",
       "3                url                0.000000\n",
       "4              state                0.000000\n",
       "5            revenue                0.000000\n",
       "6           growth_%                0.000000\n",
       "7           industry                0.000000\n",
       "9   previous_workers                0.000000\n",
       "10           founded                0.000000\n",
       "11       yrs_on_list                0.000000\n",
       "13              city                0.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the result\n",
    "the_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "> Inputs:\n",
    "\n",
    "  * the_df: a DataFrame\n",
    "  * the_col: the name of a column in the_df\n",
    "  \n",
    "> Assumptions (conditions that are required and not checked for\n",
    "  the purposes of this assignment):\n",
    "  \n",
    "  * The parameters have the expected types\n",
    "  * the_df is not empty\n",
    "  * the_col is a column in the_df\n",
    "  * the string value returned has a \"reasonable\" length\n",
    "  * the condition above is implied by this condition:\n",
    "    the length of the_df[the_col] \"reasonable\"\n",
    "  \n",
    "> Returns:\n",
    "\n",
    "  * A string indicating the number of NaN values in the_df[the_col],\n",
    "    a  list of distinct values in the column, and the types of these\n",
    "    values\n",
    "\n",
    "'''\n",
    "def col_status(the_df, the_col):\n",
    "    \n",
    "    # form the string and return it\n",
    "    col_vals = the_df[the_col]\n",
    "    the_string =  'Missing: ' + str(col_vals.isna().sum())\n",
    "    the_string += ' // ' + 'Distinct Values: ' + str(col_vals.unique())\n",
    "    the_string += ' // ' + 'Types: ' + str(set([type(x) for x in col_vals]))\n",
    "    \n",
    "    # that's it ... TBTG!!!\n",
    "    return the_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0 // Distinct Values: ['Phoenix' 'Nashville' 'Austin' 'UNKNOWN' 'Philadelphia' 'Miami'\n",
      " 'New York City' 'Richmond, VA' 'Cleveland' 'Los Angeles' 'Denver'\n",
      " 'Washington, DC' 'Seattle' 'Atlanta' 'San Diego' 'Boise City-Nampa, ID'\n",
      " 'San Francisco' 'Provo-Orem, UT' 'Tampa' 'Raleigh, NC' 'Madison, WI'\n",
      " 'Detroit' 'Houston' 'Dallas' 'Allentown-Bethlehem-Easton, PA-NJ'\n",
      " 'Minneapolis' 'Birmingham, AL' 'Boston' 'Cincinnati' 'Baltimore'\n",
      " 'Kansas City, MO-KS' 'San Jose' 'Chicago'\n",
      " 'Louisville/Jefferson County, KY-IN' 'Columbus, OH' 'St. Louis, MO-IL'\n",
      " 'Bridgeport-Stamford-Norwalk, CT' 'San Antonio, TX' 'Inland Empire, CA'\n",
      " 'Las Vegas, NV' 'Indianapolis, IN' 'Orlando, FL'\n",
      " 'Omaha-Council Bluffs, NE-IA' 'Virginia Beach' 'Lancaster, PA'\n",
      " 'Pittsburgh, PA' 'Charleston, SC' 'Jacksonville, FL' 'Salt Lake City'\n",
      " 'Milwaukee' 'Charlotte' 'Oklahoma City, OK' 'Des Moines, IA'\n",
      " 'Boulder, CO' 'Columbia, SC' 'Rochester, NY' 'Huntsville, AL'\n",
      " 'Baton Rouge, LA' 'Sacramento, CA' 'Santa Barbara-Santa Maria-Goleta, CA'\n",
      " 'Albany-Schenectady-Troy, NY' 'New Orleans' 'Ogden-Clearfield, UT'\n",
      " 'Ann Arbor, MI' 'Sarasota-Bradenton-Venice, FL'\n",
      " 'Greenville-Mauldin-Easley, SC' 'Tulsa, OK' 'Asheville, NC' 'Durham, NC'\n",
      " 'Springfield, MO' 'Oxnard-Thousand Oaks-Ventura, CA'] // Types: {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# see what the function shows for 'metro'\n",
    "print(col_status(companies_df, 'metro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Inputs:\n",
    "# \n",
    "# * the_df: a DataFrame\n",
    "#\n",
    "# * the_col: column name in the_df\n",
    "#\n",
    "# * the_rep_dict: dictionary that describes the replacements (x -> y), where\n",
    "#   x is in the set of values of the_df[the_col], and also in \n",
    "#   the set of keys of the_rep_dict, and viceversa--except when x is NaN\n",
    "# \n",
    "# * nan_val: value that is used to replace NaN in the_df[the_col], if\n",
    "#   there are any\n",
    "#\n",
    "# > Assumptions (conditions that are required and not checked for\n",
    "# the purposes of this assignment):\n",
    "#\n",
    "# * The parameters have the expected types\n",
    "# * the_df is not empty\n",
    "# * the_col is a column in the_df\n",
    "# * the set of keys of the_rep_dict is equals to the set of values \n",
    "#   in the_df[the_col] that are not NaN\n",
    "# * nan_val is not NaN\n",
    "# * It seems natural to assume that NaN is not in the set of \n",
    "#   values of the_rep_dict\n",
    "#\n",
    "# > Returns:\n",
    "# \n",
    "# * unique_vals_list: an iterable object that contains all unique values in\n",
    "#   the_df[the_col]\n",
    "# * type_vals_list: a set with the types of values in the_df[the_col]\n",
    "# * n_nan: the number of NaN values in the_df[the_col]\n",
    "#\n",
    "def replace_vals_in_df(the_df, the_col, the_rep_dict, nan_val):\n",
    "    # \n",
    "    # first replace the values that are not NaN\n",
    "    # skip if the_rep_dict is empty\n",
    "    if len(the_rep_dict) != 0:\n",
    "        the_df[the_col].replace(the_rep_dict, inplace=True)\n",
    "    # end if\n",
    "    \n",
    "    # now replace the NaN values if there are any\n",
    "    if the_df[the_col].isna().sum() != 0:\n",
    "        the_df[the_col] = the_df[the_col].fillna(nan_val)\n",
    "    # end if\n",
    "    \n",
    "    # collect returning values\n",
    "    unique_vals_list = the_df[the_col].unique()\n",
    "    type_vals_list = set([type(x) for x in unique_vals_list])\n",
    "    n_nan = the_df[the_col].isna().sum()\n",
    "    \n",
    "    # that's it ... TBTG!!!\n",
    "    return unique_vals_list, type_vals_list, n_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how to fix the NaNs by substituting it by 'UNKNOWN'\n",
    "unique_vals_list, type_vals_list, n_nan = replace_vals_in_df(the_df=companies_df, \n",
    "                                                            the_col='metro', \n",
    "                                                            the_rep_dict={}, \n",
    "                                                            nan_val='UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Phoenix', 'Nashville', 'Austin', 'UNKNOWN', 'Philadelphia',\n",
       "        'Miami', 'New York City', 'Richmond, VA', 'Cleveland',\n",
       "        'Los Angeles', 'Denver', 'Washington, DC', 'Seattle', 'Atlanta',\n",
       "        'San Diego', 'Boise City-Nampa, ID', 'San Francisco',\n",
       "        'Provo-Orem, UT', 'Tampa', 'Raleigh, NC', 'Madison, WI', 'Detroit',\n",
       "        'Houston', 'Dallas', 'Allentown-Bethlehem-Easton, PA-NJ',\n",
       "        'Minneapolis', 'Birmingham, AL', 'Boston', 'Cincinnati',\n",
       "        'Baltimore', 'Kansas City, MO-KS', 'San Jose', 'Chicago',\n",
       "        'Louisville/Jefferson County, KY-IN', 'Columbus, OH',\n",
       "        'St. Louis, MO-IL', 'Bridgeport-Stamford-Norwalk, CT',\n",
       "        'San Antonio, TX', 'Inland Empire, CA', 'Las Vegas, NV',\n",
       "        'Indianapolis, IN', 'Orlando, FL', 'Omaha-Council Bluffs, NE-IA',\n",
       "        'Virginia Beach', 'Lancaster, PA', 'Pittsburgh, PA',\n",
       "        'Charleston, SC', 'Jacksonville, FL', 'Salt Lake City',\n",
       "        'Milwaukee', 'Charlotte', 'Oklahoma City, OK', 'Des Moines, IA',\n",
       "        'Boulder, CO', 'Columbia, SC', 'Rochester, NY', 'Huntsville, AL',\n",
       "        'Baton Rouge, LA', 'Sacramento, CA',\n",
       "        'Santa Barbara-Santa Maria-Goleta, CA',\n",
       "        'Albany-Schenectady-Troy, NY', 'New Orleans',\n",
       "        'Ogden-Clearfield, UT', 'Ann Arbor, MI',\n",
       "        'Sarasota-Bradenton-Venice, FL', 'Greenville-Mauldin-Easley, SC',\n",
       "        'Tulsa, OK', 'Asheville, NC', 'Durham, NC', 'Springfield, MO',\n",
       "        'Oxnard-Thousand Oaks-Ventura, CA'], dtype=object),\n",
       " {str},\n",
       " 0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals_list, type_vals_list, n_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0 // Distinct Values: ['Phoenix' 'Nashville' 'Austin' 'UNKNOWN' 'Philadelphia' 'Miami'\n",
      " 'New York City' 'Richmond, VA' 'Cleveland' 'Los Angeles' 'Denver'\n",
      " 'Washington, DC' 'Seattle' 'Atlanta' 'San Diego' 'Boise City-Nampa, ID'\n",
      " 'San Francisco' 'Provo-Orem, UT' 'Tampa' 'Raleigh, NC' 'Madison, WI'\n",
      " 'Detroit' 'Houston' 'Dallas' 'Allentown-Bethlehem-Easton, PA-NJ'\n",
      " 'Minneapolis' 'Birmingham, AL' 'Boston' 'Cincinnati' 'Baltimore'\n",
      " 'Kansas City, MO-KS' 'San Jose' 'Chicago'\n",
      " 'Louisville/Jefferson County, KY-IN' 'Columbus, OH' 'St. Louis, MO-IL'\n",
      " 'Bridgeport-Stamford-Norwalk, CT' 'San Antonio, TX' 'Inland Empire, CA'\n",
      " 'Las Vegas, NV' 'Indianapolis, IN' 'Orlando, FL'\n",
      " 'Omaha-Council Bluffs, NE-IA' 'Virginia Beach' 'Lancaster, PA'\n",
      " 'Pittsburgh, PA' 'Charleston, SC' 'Jacksonville, FL' 'Salt Lake City'\n",
      " 'Milwaukee' 'Charlotte' 'Oklahoma City, OK' 'Des Moines, IA'\n",
      " 'Boulder, CO' 'Columbia, SC' 'Rochester, NY' 'Huntsville, AL'\n",
      " 'Baton Rouge, LA' 'Sacramento, CA' 'Santa Barbara-Santa Maria-Goleta, CA'\n",
      " 'Albany-Schenectady-Troy, NY' 'New Orleans' 'Ogden-Clearfield, UT'\n",
      " 'Ann Arbor, MI' 'Sarasota-Bradenton-Venice, FL'\n",
      " 'Greenville-Mauldin-Easley, SC' 'Tulsa, OK' 'Asheville, NC' 'Durham, NC'\n",
      " 'Springfield, MO' 'Oxnard-Thousand Oaks-Ventura, CA'] // Types: {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# also\n",
    "print(col_status(companies_df, 'metro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function can be used to deal with multiple substitutions within a column through the parameter `the_rep_dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 How would you code a Python class that you can use to make `GET` API calls in a wide variety of projects that require the use of REST APIs to acquire datasets?\n",
    "\n",
    "When acquiring data from providers that expose them through [REST APIs](https://aws.amazon.com/what-is/restful-api/) one can easily drown in repetitious code, which can become very difficult to maintain.\n",
    "\n",
    "I once worked for a Sports Analytics start-up that acquired most of their data through a provider called [Sportradar](https://developer.sportradar.com/) who exposes their data through a REST API.\n",
    "\n",
    "For instance, information associated with the (so-called) Daily Boxscore, of all the [MLB](https://www.mlb.com/) games played in a scheduled game of a season, is exposed through a `GET` [API call](https://developer.sportradar.com/docs/read/baseball/MLB_v7_with_Statcast#daily-boxscore). For those not familiar with US Baseball, the boxscore of a game is the \"<i>Inning-by-inning scoring breakdown, top-level runs, hits and errors by team, as well as details on run-scoring events</i>\"--as described by Sportradar.\n",
    "\n",
    "The code below exemplifies how an object of such class can be instantiated, and then be used to make the `GET` call through an instance method of the class.\n",
    "\n",
    "A common practice across many data providers is that the results returned after a successful `GET` API call are represented using the [JSON format](https://www.json.org/json-en.html).\n",
    "\n",
    "The specific class shell that I am sharing with you has a method called `make_get_request_paginated(api_end_point, object_name)` which requires the indicated parameters, where `api_end_point` contains the string associated with the `GET` API endpoint of interest (in this case, the one associated with getting the Boxscore of a game), and `object_name` is a string that defines the component from the response that one wants to extract.\n",
    "\n",
    "Notice the following:\n",
    "\n",
    "* The information associated with the credentials needed to use the API are encapsulated in a configuration file, the name of which is passed to the constructor of the class. When credentials are stored in a configuration file, they are usually kept unencrypted, which is better than hard-coding them in the source code. But the best practice is to use a service such as [AWS Secret Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/retrieving-secrets.html), which keeps the secret encypted.\n",
    "\n",
    "\n",
    "* Support for [exception](https://docs.python.org/3/tutorial/errors.html) and error handling, as well as [logging](https://docs.python.org/3/howto/logging.html) must also be implemented.\n",
    "\n",
    "\n",
    "* The class takes into account `GET` requests that use pagination, which means that several calls might be needed to get the complete information associated with an endpoint. Typically, a loop is implemented to get the information while there are more pages to be served, and all the information is collected and returned by the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of use of class XXX_API_V2_GET_Caller\n",
    "\n",
    "# create object: constuctor can raise the ValueError exception\n",
    "# config file has the required credentials (non-encrypted)\n",
    "# best practice: use something like AWS Secret Manager instead\n",
    "# REF: https://docs.aws.amazon.com/secretsmanager/latest/userguide/retrieving-secrets.html\n",
    "config_file_name = 'XXX_config.txt'\n",
    "try:\n",
    "    XXX_api_v2_get_caller = XXX_API_V2_GET_Caller(config_file_name, DEBUG=False)\n",
    "except ValueError as e:\n",
    "    logging.debug(f'An error occurred: {e}')\n",
    "    # raise error again so it is caught by the global exception handler\n",
    "    # which will log the error and decide whether to exit the application\n",
    "    raise\n",
    "\n",
    "# the API endpoint is associated with the type of information we\n",
    "# want to get    \n",
    "api_end_point = XXX\n",
    "\n",
    "# the object name defines the component from the\n",
    "# call result we are interestes in\n",
    "object_name = XXX\n",
    "\n",
    "# use method make_get_request_paginated\n",
    "# to make the call ... in this case, we\n",
    "# know that the API uses pagination to return their\n",
    "# results--meaning: one has to make several calls to\n",
    "# get all the results of a request ... these details\n",
    "# are encapsulated in the implementation of the class\n",
    "message, xxx_json = xxx_api_v2_get_caller.make_get_request_paginated(api_end_point, object_name)\n",
    "\n",
    "# check if the call was OK\n",
    "# if xxx_json is None something happened\n",
    "# and message should have the info explaining\n",
    "# what happened\n",
    "if xxx_json is None:\n",
    "\t# the call did not go as planned so there\n",
    "\t# log the error mesage\n",
    "\tlog_critical_event(message)\n",
    "else:\n",
    "    # we are interested in the object associated with key object_name\n",
    "    xxx_entries_list = xxx_json[object_name]\n",
    "\n",
    "    # we are assuming that we have some function that\n",
    "    # takes the result and processes it\n",
    "    process_result(xxx_entries_list)\n",
    "# end if-else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the class \"shell\" I am sharing with you. This means that the code cannot be used as-is. However, you can use the code to guide you in the implementation of your own class--and I hope it will be useful :-D\n",
    "\n",
    "I encourage you to adapt it so you can use it in the \"API Mini-Project\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************************************************\n",
    "#\n",
    "# RESOURCES\n",
    "# \n",
    "# ********************************************************************************\n",
    "\n",
    "# OS and JSON support\n",
    "import os\n",
    "import json\n",
    "\n",
    "# request library\n",
    "# https://github.com/psf/requests\n",
    "# https://requests.readthedocs.io/en/latest/\n",
    "import requests\n",
    "\n",
    "# to read a dict from config file\n",
    "import ast\n",
    "\n",
    "# needed to define a global exception handler\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# typing notation\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Dict\n",
    "\n",
    "# for logging\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class XXX_API_V2_GET_Caller:\n",
    "    '''\n",
    "    PURPOSE:\n",
    "    This class creates an object that can implement any GET request\n",
    "    to the XXX API V2.\n",
    "    REF: https://...\n",
    "    '''\n",
    "\n",
    "    # class constants: private to this class\n",
    "    __AUTH = None           # XXX token\n",
    "    __ACCOUNT = None        # XXX account_id\n",
    "    __headers = None        # Used in the API call\n",
    "    __BASE_URL = None       # Used in the API call\n",
    "    # info about XXX API authentication expected to be\n",
    "    # in the configuration file\n",
    "    __expected_keys = None\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, config_file_name:str, DEBUG:bool=False) -> None:\n",
    "        '''\n",
    "        PURPOSE:\n",
    "        Creates a new object using information in the file\n",
    "        named by config_file_name.\n",
    "\n",
    "        Args:\n",
    "            config_file_name: ditto\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if config_file does not exist in the same folder where the code is, OR\n",
    "            if the value in the file is not well-formed, OR the value in the file does not\n",
    "            contain exactly the columns named per private constant __expected_keys\n",
    "           \n",
    "        '''\n",
    "\n",
    "        # get info from config_file_name, uses private helper class __get_credentials\n",
    "        XXX_API_V2_GET_Caller.__expected_keys = ['XXX_account_id', 'XXX_token'] \n",
    "        message, config_dict = self.__get_credentials(config_file_name,  XXX_API_V2_GET_Caller.__expected_keys)\n",
    "\n",
    "        # check if there were any errors; if such, raise an exception\n",
    "        if config_dict is None:\n",
    "            raise ValueError(message)\n",
    "        \n",
    "        # all OK, set the values of class constants\n",
    "        XXX_API_V2_GET_Caller.__AUTH = config_dict['XXX_token']\n",
    "        XXX_API_V2_GET_Caller.__ACCOUNT = config_dict['XXX_account_id']\n",
    "        XXX_API_V2_GET_Caller.__headers = {\n",
    "            \"User-Agent\": \"Trying XXX Python API (XXX@XXX.com)\",\n",
    "            \"Authorization\": \"Bearer \" + XXX_API_V2_GET_Caller.__AUTH,\n",
    "            \"XXX-Account-ID\": XXX_API_V2_GET_Caller.__ACCOUNT}\n",
    "        XXX_API_V2_GET_Caller.__BASE_URL = 'https://api.XXXapp.com/v2/'\n",
    "\n",
    "        if DEBUG:\n",
    "            print('[__init__]\\n\\t __AUTH: ' + str(XXX_API_V2_GET_Caller.__AUTH) + \\\n",
    "                  '\\n\\t __ACCOUNT: ' + str(XXX_API_V2_GET_Caller.__ACCOUNT))\n",
    "        # end if\n",
    "\n",
    "        \n",
    "\n",
    "    def __get_credentials(self, config_file_name: str, expected_keys: list[str]) -> Tuple[str, Dict[str, str]]:\n",
    "        '''\n",
    "        PURPOSE:\n",
    "        Helper function that tries to read the value of a dict stored\n",
    "        in file config_file_name, and such value is expected to have \n",
    "        the keys given by expected_keys, which is a list of names.\n",
    "\n",
    "        V8 (XX/XX/XXXX): the config file might have additional keys than\n",
    "        the ones in expected_keys. The condition has been relaxed so\n",
    "        that for the purposes of this function, expected_keys\n",
    "        should be a *subset* of the set of keys in the config file.\n",
    "\n",
    "        ERRORS:\n",
    "        * config_file_name does not exist\n",
    "        * config_file_exists, but the contents of the file is not a valid dict value\n",
    "        * config_file_exists, the contents of the file is a valid dict value, but the\n",
    "        keys in this dict are not the ones in expected_keys\n",
    "\n",
    "        RETURNS: \n",
    "        A pair message, dict with values according to:\n",
    "        * if there are errors, the message indicates the error, and the dict is None\n",
    "        * if there are no errors, the message is the empty string, and the dict is the value in the file\n",
    "        '''\n",
    "\n",
    "        # check if config_file_name exists in the current directory\n",
    "        # if it does not exist, return message, None; where the message\n",
    "        # explains that the file does not exist\n",
    "\n",
    "        # get current dir\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        # check if file exists\n",
    "        the_path = os.path.join (current_dir, config_file_name)\n",
    "        if  os.path.exists (the_path) == False:\n",
    "            # file does not exist, return message and None\n",
    "            message = '[Constructor of class XXX_API_GET_Caller]: file '\n",
    "            message += config_file_name + ' does not exist in current directory: '\n",
    "            message += current_dir\n",
    "            return message, None\n",
    "        # end if\n",
    "\n",
    "        # at this point, we know that config_file_name exists in current directory\n",
    "\n",
    "        # try to get the info\n",
    "        # use exception handling to read the config_file_name\n",
    "        # should try to set config_dict after reading the config_file_name file\n",
    "        with open(config_file_name) as dict_contents:\n",
    "            try:\n",
    "                config_dict = ast.literal_eval(dict_contents.read())\n",
    "            except (ValueError, SyntaxError, Exception) as e:\n",
    "                message = '[__get_credentials] Issues reading the contents of config file: ' + \\\n",
    "                          config_file_name + ' ... ' + str(e.msg)\n",
    "                return message, None\n",
    "\n",
    "        # V8: check if the keys in the dict are a super-set of the\n",
    "        # expected keys (iff set_expected_keys is contained in set_actual_keys)\n",
    "        set_expected_keys = set(expected_keys)\n",
    "        set_actual_keys = set(config_dict.keys())\n",
    "        if set_expected_keys.issubset(set_actual_keys) == False:\n",
    "             message = '[__get_credentials] ERROR: expected keys are: '\n",
    "             message += str(set_expected_keys)\n",
    "             message += '; and actual keys are: ' + str(set_actual_keys)\n",
    "             message += '; expected keys must me a SUBSET of actual keys ...'\n",
    "             return message, None\n",
    "        # end if\n",
    "        \n",
    "        # no issues at this point ... return '' and the config_dict read\n",
    "        return '', config_dict\n",
    "\n",
    "    # end __get_credentials\n",
    "\n",
    "    # some simple getters to be used to test class\n",
    "    def get_auth(self) -> str:\n",
    "        return self.__AUTH\n",
    "    \n",
    "    def get_account(self)-> str:\n",
    "        return self.__ACCOUNT\n",
    "    \n",
    "    def get_base_url(self) -> str:\n",
    "        return self.__BASE_URL\n",
    "    \n",
    "    def get_headers(self) -> str:\n",
    "        return self.__headers\n",
    "    \n",
    "    def make_get_request(self, api_end_point: str) -> Tuple[str, Dict[str, str]]:\n",
    "        '''\n",
    "        PURPOSE:\n",
    "        This method attempts to make a GET call to api_end_point\n",
    "\n",
    "        RETURNS:\n",
    "        A message indicating whether or not there were errors in the call (empty if no errors),\n",
    "        and a dict that represents the JSON object returned by the request\n",
    "        when there are no errors (None if there are errors)\n",
    "\n",
    "        '''\n",
    "\n",
    "        # set url\n",
    "        url = self.__BASE_URL + api_end_point\n",
    "\n",
    "        # make a GET call with url and consider possible errors\n",
    "        try:\n",
    "            # get the response object\n",
    "            response = requests.request(\"GET\", url, headers=self.__headers)\n",
    "            # rise an exception as indicated by response.status_code\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            message  = f'An error occurred: {e}'\n",
    "            message += f' ... Status code: {response.status_code}'\n",
    "            message += f' ... Response: {response.text}'\n",
    "            return message, None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            message = f'Response: {response.text}'\n",
    "            return message, None\n",
    "        except Exception as e:\n",
    "            message = f'Response: {response.text}'\n",
    "            return message, None\n",
    "        # end try-except\n",
    "\n",
    "        # all is well, return no message and the JSON dict associated\n",
    "        # with response\n",
    "        return '', response.json()\n",
    "    \n",
    "    # end make_get_request\n",
    "    \n",
    "    def make_get_request_paginated(self, \n",
    "                                   api_end_point: str,\n",
    "                                   object_name: str) -> Tuple[str, Dict[str, str]]:\n",
    "        '''\n",
    "        PURPOSE:\n",
    "        Attempts to make a GET request for the given api_end_point, and if all goes\n",
    "        well, it returns a pair (message, dict), where message is the empty string, and\n",
    "        dict is a dictionary, that has just one key, which must be equals to object_name,\n",
    "        and the value of this key must be a list of JSON objects, captured over all the\n",
    "        pages associated with api_end_point.\n",
    "\n",
    "        This method repeatedly calls make_get_request to get each individual page associated with this\n",
    "        request.\n",
    "\n",
    "        If there are any errors--all of which are handled by method make_get_request--the\n",
    "        returned pair (message, dict) is such that message contains a description of the\n",
    "        error, and dict is None.\n",
    "\n",
    "        NOTE: when this method is called with an api_end_point that does not use pagination\n",
    "        by definition (for instance https://...)\n",
    "        then this method will behave in exactly the same way as method  make_get_request(self, api_end_point) does,\n",
    "        and thus argument 'object_name' is ignored.\n",
    "        '''\n",
    "\n",
    "        # method body\n",
    "\n",
    "        # make the first call to determine:\n",
    "        # (a) if an error occurs with the first call\n",
    "        # (b) if there are no errors, and there are no\n",
    "        # multiple pages to process\n",
    "        # (c) if there are no errors, and there are\n",
    "        # multiple pages to process\n",
    "\n",
    "        first_message, first_response_json = self.make_get_request(api_end_point)\n",
    "\n",
    "        # case (a): some error in the first request\n",
    "        if len(first_message) != 0:\n",
    "            return first_message, None\n",
    "        # end case (a)\n",
    "\n",
    "        # case (b): no errors and two subcases to consider\n",
    "        TOTAL_PAGES = 'total_pages'\n",
    "        # NOTE: per the documentation ...\n",
    "        #\n",
    "        # \" XXX\"\n",
    "        #\n",
    "        # ref: https://...\n",
    "        \n",
    "        # case (b.1): the api_end_point does not use pagination at all\n",
    "        # (see the NOTE) at the beginning of this method\n",
    "        # in this case, we just return what self.make_get_request(api_end_point)\n",
    "        # has returned\n",
    "        if TOTAL_PAGES not in first_response_json.keys():\n",
    "            return '', first_response_json\n",
    "        #end of case (b.1)\n",
    "\n",
    "        # case (b.2): the api_end_point does use pagination, but the total number\n",
    "        # pages is 1. In this case, we need to return the portion of first_response_json\n",
    "        # associated with object_name\n",
    "        # NOTE: I use str(first_response_json[TOTAL_PAGES]) below, because I am not sure what is the type\n",
    "        # of the expression\n",
    "        if TOTAL_PAGES in first_response_json.keys() and str(first_response_json[TOTAL_PAGES]) == '1':\n",
    "            # prepare the object to return\n",
    "            object_reponse_dict = {}\n",
    "            object_reponse_dict[object_name] = first_response_json[object_name]\n",
    "            return '', object_reponse_dict\n",
    "        # end of case (b.2)\n",
    "\n",
    "        # case (c): there are no errors and the total number of pages is recorded\n",
    "        # in first_response_json[TOTAL_PAGES] and it is not equals to '1'\n",
    "        #\n",
    "        # try to convert first_response_json[TOTAL_PAGES] to int\n",
    "        try:\n",
    "            total_pages = int(first_response_json[TOTAL_PAGES])\n",
    "        except ValueError as e:\n",
    "            message = '[make_get_request_paginated] Rare Error: exception raised when trying to convert total_pages field '\n",
    "            message += TOTAL_PAGES + ' of response to this GET api_call: ' + api_end_point + ' offending value is: '\n",
    "            message += str(first_response_json[TOTAL_PAGES])\n",
    "            return message, None\n",
    "        # end try-catch block\n",
    "\n",
    "        # total_pages contains the number of pages to be retrieved and must be greater than 1\n",
    "        # initialize variables before the loop\n",
    "        # to keep track of pages ... add first page\n",
    "        # NOTE: the logic below would work even when the total number of\n",
    "        # pages is 1, since the loop would be skipped and the method would\n",
    "        # return the expected value\n",
    "        LINKS = 'links'\n",
    "        NEXT = 'next'\n",
    "        # ref: https://...\n",
    "        current_response_json  = first_response_json\n",
    "        response_list = current_response_json[object_name]\n",
    "        for n_pages in range(2, total_pages + 1):\n",
    "            # get URL from current_response_json\n",
    "            next_url = current_response_json[LINKS][NEXT]\n",
    "            # get api_end_point to call make_get_request(self, api_end_point: str)\n",
    "            # next_url is expected to have a structure such as\n",
    "            # \"https://...\",\n",
    "            # so the api_end_point should be the second component of the split of next_url and self.__BASE_URL\n",
    "            api_end_point = next_url.split(self.__BASE_URL)[1]\n",
    "            # make a call with this api_end_point\n",
    "            message, current_response_json = self.make_get_request(api_end_point)\n",
    "            # check if there are errors\n",
    "            if len(message) != 0:\n",
    "                error_message = '[make_get_request_paginated] ' + message\n",
    "                return error_message, None\n",
    "            # end if\n",
    "            # all is well ... TBTG!!!\n",
    "            # add current page's response to response_list\n",
    "            response_list += current_response_json[object_name]\n",
    "            # continue iteration--if any\n",
    "        # end for\n",
    "\n",
    "        # return dict with all the pages currently in response_list\n",
    "        object_reponse_dict = {}\n",
    "        object_reponse_dict[object_name] = response_list\n",
    "        return '', object_reponse_dict\n",
    "    \n",
    "        # end case (c)\n",
    "\n",
    "    # end make_get_request_paginated ...TBTG!!!\n",
    "\n",
    "# end class XXX_API_GET_Caller ... TBTG!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs_sandbox_env_plus",
   "language": "python",
   "name": "vs_sandbox_env_plus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
